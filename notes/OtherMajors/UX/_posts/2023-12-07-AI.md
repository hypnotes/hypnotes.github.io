---
layout: post
title: Artificial Intelligence
description: >
sitemap: false
permalink: /notes/UX/AI
---

- this list will be replaced by the toc
{:toc .large-only}

옛날: 자동화 vs 인간제어

|   자동화    |  인간제어    |
| :---------: | :---------: |
| deductively | inductively |
| 연역적 사고  | 귀납적 사고  |

$$\Rightarrow$$ 더 이상 대립관계가 아닌, 상호보완적 관계로 바뀜
- 사로 닮아가는 기계와 인간 
- 기계가 연역적 사고를 한다는 것은 outdated, 이제 맥락 내 융통성, 유연함 등 인간의 고유 속성이라고 일컬여진 것들이 가능함

## Robots
---

### 🤖 로봇공학 제 3원칙
by Isaac Asimov

> 1. 로봇은 인간에게 해를 가하거나 행동을 하지 않음으로써 인간에게 해가 가도록 해서는 안된다
> 2. 로봇은 인간에게 복종해야 한다 (단, 1번을 위배할 때 제외)
> 3. 로봇은 자신의 존재를 보호해야 한다 (단, 1, 2번을 위배할 때 제외)

추후 추가된 0번
> **아무것도 하지 않음으로써** 인간에게 해를 끼칠 수 없어야 한다.

- 참고: [Rome Call for AI Ethics](https://www.romecall.org/)

### 🥸 클라크의 세 가지 법칙
by Arthur C. Clarke

> 1. 어떤 뛰어난 노년의 과학자가 무언가가 가능하다고 말한다면, 그는 거의 항상 옳다. 하지만 그가 무언가가 불가능하다고 말한다면, 그는 거의 틀리다.
> 2. 그 가능성의 한계를 발견하는 유일한 방법은 **불가능의 영역**으로 조금 더 나아가는 것이다.
> 3. 고도로 발달한 기술은 마법과 구분할 수 없다.

### 🧙‍♂️ 현실적 몽상가들
아서 클라크와 로버트 하인라인

- 아서 클라크: 2001 스페이스 오디세이, 2010, 2061, 3001
- 로버트 하인라인: I, Robot

**그들이 그렸던 미래**는 이제 **우리가 살아가고 있는 현재**이다. 그들의 사고는 학문적으로 뒷받침 받았고, 사회맥락적 이해에 근거했다.

$$Q.$$ 우리도 현실적 몽상가들이 될 준비가 되어 있는가

$$Q.$$ 미래 사회에 인공지능을 어떻게 볼 것이고, 사회 구성원으로 어떻게 받아드릴 것인가? 

## Artificial Intelligence
---

### 🫢 인공지능에 대한 신뢰

- 인공지능 규제 필요성 vs 가치 중립성
- Robot Civil Rights Act (2017, European Commission)
    - 로봇시민법, 로봇에게 권리를 부여하자는 법안
- 윤리의식을 가르치기 전, 우리가 먼저 이를 명확하게 정의해야 함
    - 해를 끼치지 않게 가르치려면 `해`가 무엇인지에 대한 정의 필요
    - 인공지능은 **동반자**의 수준을 넘어서면 안된다

**사람은 얼마나 인공지능을 신뢰하는가**

- 신뢰를 무너뜨리는 것들 
    - MS, Amazon에서 채용 시 사용한 인공지능이 남녀차별, 인종 차별을 일으켜 사용을 중단함
    - Malicious AI : 의도적으로 판다에 노이즈를 추가했을 때 긴팔 원숭이로 인식하게 됨 -> 사용자가 악의적으로 조작할 수 있다는 것을 보여줌

### 📒 신뢰할만한 인공지능을 위한 윤리 지침 

`2019` European Commision에서는 인간 중심의 관점에서 인공지능에 대한 신뢰 구축 필요성 강조. 이를 위해 `Ethics Guidelines for Trustworthy AI`를 발표함 윤리, 인문, 사회, 문화적 접근의 중요성이 재조명됨

**신뢰할만한 인공지능 Framework**

1. 합법적 (Lawful) AI
    - 기반: 기본권에 대한 윤리적 원칙 준수
    - 구현: 필수 요구조건 실행
    - 평가: 요구조건 만족 여부 평가
2. 윤리적 (Ethical) AI
    - 4 ethical 원칙들 사이 충돌을 이해하고 다룸
    - 7가지 필수조건 (기술적, 비기술적)을 개발 주기 전반에 걸쳐 꾸준한 평가 및 검토
    - 신뢰할만한 인공지능 평가 지표 
3. 강건한 (Robust) AI
    - **4 ethical 원칙**
        1. 인간 자율성에 대한 존중
        2. 해에 대한 방지
        3. 공정성
        4. 설명력 (설명 가능성)
    - **7가지 필수조건**
        1. 인간의 관리 및 감독 (원할 때 인간이 제어할 수 있어야 함)
        2. 기술적 견고성과 안전성
        3. 개인정보 보호, 데이터 통제
        4. 투명성
        5. 다양성, 비차별성, 사회적 공정성 **
        6. 환경 및 사회적 복지 (ESG)
        7. 책무성

### 💬 Explainable AI

- high performance AI systems + human-understandable explanations, provable, transparent $$\Rightarrow$$ **gain user trust**

- interface의 역할이 중요해질 것 (설명해주는 상호작용의 창구)

- 연구분야
    - explainable model (AI) 예측과정에 대한 설명
    - explainable interface (HCI) 설명을 어떻게 제공할 것인가
    - user characteristics (Psychology) 사용자의 특성에 따라 설명을 어떻게 제공할 것인가

### 🧠 초거대 인공지능

- 인공지능에서 데이터는 매우 중요한 자원, 라벨링, 전처리 과정, 특정 도메인 지식 등이 덧입혀진 뒤 사용됨

인공신경망의 parameter이 커지는 중이다
- 인간의 뇌를 모방하려는 시도
- embedding, attention, transformer 등의 기술이 발전하면서 parameter가 늘어남
- 초거대 인공지능은 이러한 데이터를 모으는 과정을 여럿생략하고, 지식을 바탕으로 학습함

**인공지능의 한계**
- 현재의 인공지능: 목표 명확한 문제에 적합 
    - 없다면 '알아서 하기'가 어려움, 중립적 사고에 기반한 추론의 확장이기에 
- 상식 학습이 굉장히 어려움. **맥락**이라는 요소가 필요하기 떄문
- 인간의 뇌는 맥락을 이해하고, 추론을 통해 문제를 해결함
- 특히나 객관화가 거의 불가능한 **감정**에서 최대 어려움을 겪고 있음 

> The question is not whether intelligent machines can have any emotions, but whether machines can be intelligent without any emotions. - Marvin Minsky