---
layout: post
title: Corpus
description: >
  Fundamentals of Corpus Knowledge
# image: /assets/img/blog/example-content-ii.jpg
sitemap: false
# permalink: /notes/R/Corpus
categories: r
---

* this list will be replaced by the toc
{:toc .large-only}

### 강의 개요

- **텍스트** 
    - 텍스트 데이터를 다루는 방법을 찾는다
    - 언어 사용 특성 반영
    - 미지의 자원

- **Corpus**
    - 대규모의 음성 / 텍스트 데이터 (언어 연구 목적)
    - <mark>보편성 관찰</mark>: 대표성 (Representativeness)과 균현성 (balance) 고려함
    - <mark>개별성 관찰</mark>: 코퍼스의 구분 변수 활용 
    - 가장 중요한 Storytelling

텍스트 마이닝의 이유 : <br>
**계량적 / 통계적 분석**을 통해 코퍼스 및 텍스트로부터 **숨겨져 있는** (or **인간의 직관으로 발견하기 어려운**) **유의미한 정보/지식/의미/가치를 도출**하기 위해
{:.note}

- 중요! : **관찰력과 문제해결능력(질문)**

#### 빅데이터 시대와 프로그래밍 언어

- 데이터 수집 => 가공 => 분석/시각화 => 해석/스토리텔링
- 빅데이터 환경
    - 대규모의 데이터 (수작업 불가능) : 컴퓨터 활용 
    - **비정형 데이터** (정리X, 가공X)가 대다수
    - 데이터 형식의 **변환** 및 기존 데이터와의 **결합** 필요
    - 새로운/다양한 분석 기법, 시각화 활용 필요
- 데이터 분석을 위해서
    - 정렬된 데이터 필요
    - 상황에 따라 데이터 입력 형식 요구

| R                         | Python               | 
|:--------------------------|:---------------------|
| 통계학자가 개발            | 일반적목적           | 
| 디폴트: 데이터분석 환경    | import pandas, matplotlib, pandas 등등 필요 | 

# Corpus

### 역사

- 통계학과 시작과 핵심은 **<mark>표본</mark>** (Sample)
- Kiaer (Norway's first 통계청장, 1895)
    - 역사가 길지 않음
    - 모집단의 축소판인 표본 조사 제안 (<fontcolor>sample = miniature population</fontcolor>)
    - 표본의 <fontcolor>대표성 (representativeness)</fontcolor> 에 대한 개념 제안
- Jerzy Neyman ( UC Berkeley 통계학 교수, 1934)
    - 표본 구성 중요도: <fontcolor>무작위 표본추출 (random sampling)</fontcolor> > 표본 크기 늘리기 (빅데이터 처럼)
- sample size small ⇒ 오차범위 big  → 표본이 클수록 좋긴 함
    - random sampling 전제 하에: (모집단의 특성을 적절히 반영 했을 때)
    - 일정 수준 표본 크기가 넘으면 오차범위 유사 (최소 1천 텍스트 recommended)

    - <details>
        <summary>표본 크기에 따른 오차범위 차트</summary>
        <div markdown="1">

            | Population Size  | + 3 %  | + 5 %  | + 10 %  | 
            |------------------|--------|--------|---------|
            | 500              | 345    |  220   | 80      |
            | 1,000            | 525    |  285   | 90      |
            | 3,000            | 810    |  350   | 100     |
            | 5,000            | 910    |  370   | 100     |
            | 10,000           | 1,000  |  400   | 100     |
            | 100,000          | 1,100  |  400   | 100     |
            | 1,000,000        | 1,100  |  400   | 100     |
            | 10,000,000       | 1,100  |  400   | 100     |
            
            * 일정 수준 넘어가면 오차범위는 비슷하기 때문에 표본 크기를 늘리면 cost만 높아질 가능성 有
        </div></details>
    

### 기본적 표본 추출 방법

- <fontcolor>우연성</fontcolor>

    1 )  단순 무작위 표본 추출 (simple random sampling)  ex) 난수, 제비뽑기
    
    2)   체계적 표본 추출 (systematic sampling)               ex) 첫 survey 뒤 100번째 지나가는 사람
    
        - 첫 sample 만 random, 그 뒤로는 일정 간격으로 추출
    
    ⇒ 개체가 표본에 포함될 동등한 기회 제공
    
- <fontcolor>층화 표본 추출 (stratified sampling)</fontcolor>: 분포 고려
    - 모집단을 구성하는 층화/집단의 분포 비율을 고려 and 표본 추출 (층화 내에서는 우연성 통해 추출한다)
    - ex) 여론조사: 지역, 직업, 사회, 나이, 성별
    - ex2) 코퍼스:  장르별, 시기별, 인구통계학적 분포

### 코퍼스 Corpus : 

- 언어 연구 대상이 될 수 있는 (아직 관찰/측정X) **<fontcolor>전산화된 문자 txt | 음성 자료의 집합</fontcolor>**

**의미**:

- 협의적/ 일반적 의미 (narrow def) :<br>
    > 언어 연구 목적으로 {대표성, 균현성, 크기} 고려, 정교하게 설계, 구축
    - 종류: [ 장르:문어&구어 / 방언 / 사용자 특성 / 역사적 시기 / 언어학습&습득 / 언어비교 ]
    - 언어 분석 정보: 원문 (raw) / 형태소 분석 / 어휘 의미 / 구문 분석
- 광위적 의미 (broad def) :<br>
    > 언어 목적 이외에도 다양한 목적으로 활용 가능한 전산화된 자료
    - 대표성 균현성 고려할 필요 없음
    - ex) 웹문서, 트위터, 페이스북, 전산 텍스트 etc

**가치**

- 언어학적:  <br>
    - 모국어 화자의 <underline> 언어지식+언어 사용 특성</underline>이 반영된 대규모 언어 데이터
    - 인위적으로 생성 X, 실제 의사소통적 맥락 반영됨
    - 직관적으로 판단 어려운 친숙성 효과
    
      ex) 어휘, 문법, 의미, 담화, 방언, 언어 교육, 사회언어학, 심리언어학, 역사언어학 etc
    
- 인문사회과학/공학적: <br>
    - 공동체의 관심사/메시지 반영된 텍스트
    - 정보검색 등 → 컴퓨터를 이용한 데이터의 신속하고 정확한 저장, 검색, 분류, 계산
    - 확률적 분포 정보 추출/학습 in 전산언어학 or 기계학습

### 대표성과 균현성

- **통계** 

    - 모집단 (population): 연구대상 전체 집단 (But 전수 조사 어려움)

        <fade>ex) 대통령 선거 여론 조사 ⇒ 대한민국 성인 전체</fade>

    - 표본 (sample) : 모집단을 대신해서 특성을 관찰할 수 있는 부분 집합 (관촬 규모 축소)
        - <bold>대표성</bold> (representativness ) = 표본의 크기 + 균현성 (balance)
        
        <fade>ex) 대통령 선거 여론 조사 ⇒ 성별, 지역별, 나이별 등 인구비례 및 통계적 표본크기 고려</fade>

- **코퍼스** 
    - 코퍼스 설계:  <underline>variation (변이성)</underline> + 균현성 & 크기 ⇒ 설계
        - 설계만 1~2년, 보편성 변이성 관찰 목적

    
    - 표본으로서 코퍼스: sample from {언어 사용 모집단}, 관찰 규모 축소된, 특성이 반영됨
    - 모집단으로서 코퍼스: 참조 코퍼스 (reference), 개별 텍스트 특성과 비교하기 위한 모집단

### Brown Corpus

> **world's first** 코퍼스, 1960's in Brown Univ.

- 영어 어휘 출현 빈도 관찰
- 2000words x 500 sample texts = 100만 어휘
- {신문 18%, 정보책: 57%, 문학책: 25%)
- 표본 추출 방법: 층화 표본 추출 + 단순 무작위적 표본 추출
    - 장르별로 선 분류 후 그 안에서 제비뽑기

### BNC (British National Corpus): 

> 영국 표준 영어 대상, 1억 규모의 코퍼스

- 대표성, 균현성 유지를 위한 설계 기준
    - 장르의 다양성 유지
    - 화자/작가의 성, 나이같은 변수 고려
    - 영국 주요 방언 지역 대표할 수 있도록 인구 통계학적 분포 고려
    - 사회 계층 분포 고려

### 21세기 세종계획 코퍼스: 

> 언어 자원을 구축/보급, 정보화 사회에서의 언어정보 처리를 위한 국가적 과제


**다양한 코퍼스 (**에 따라 설계 방법도 달라짐**)**

- 언어적 측면 ( 외국인 학습자, 언어습득, 언어장애환자, 방언, 음성, 감성분석)
- 역사문화적 측면 (조선왕조실록 etc)


## 코퍼스 언어학

       **강범모 (2011)**

- 전산언어 자원 구축 ⇒ 컴퓨터 언어연구          자원: 코퍼스/말뭉치, 전자 사전
- 지향점:
    - 코퍼스: 연구자의 관찰 한계를 넘는 규모의 데이터,
        - 언어 사용의 변이성 및 보편성이 반영된 데이터
    - 통계: 인간의 눈으로 관찰불가능한 것들을 관찰할 기회 제공하는 도구 like 망원경, 현미경
        - 언어학작의 직관으로 포착 어려웠던 것들을 포착할 기회 제공 ⇒ hidden knowledge discovery
- 기존 코퍼스 언어학 연구의 한계:
    - 제한된 범위의 연구 방법 (제한된 통계 기법 사용, 육안 사용 등)
    - 활용 도구에 지나친 의존성 (다양한 형식 다루기X, 제한된 범위)
    
    ⇒ What 's the problem? 활용 도구의 한계, 데이터 가고 능력 부족, 통계 기법 학습 빈약
    

**전산언어학 관점의 코퍼스 언어학**

- 홍윤표 ( 2012 )
    - 국어를 이용한 {인간-컴퓨터}의 의사소통 관련된 연구 활동
    - 언어 자원: 코퍼스언어학, 전산사전학
    - 언어 분석과 생성: 전산언어학/자연어처리 (음성, 음운..etc)
    - 응용 기술: 정보 검색, 기계 번역, 기계학습 등
- 1950-1980: 문법이론 중심의 전산적 활용
- 1990-현대: 코퍼스 이용한 전산적 활용

**전산언어학: 1990년대 이후**

- 1990년대 자연언어처리의 흐름:
    - 응용가능, 원리적X.  실제 구현 가능한 기술 개발 요구
    - 통계적 접근의 활성화 ⇒ 언어학과 자연언어처리의 교류 감소
- 코퍼스를 이용한 기계학습
    - BNC, 세종코퍼스 etc 국가 주도 대용량 코퍼스 구축
    - using that, 언어 규칙/패턴 학습 ⇒ 실제 응용가능한 자연언어처리 시스템 연구
    
    왜 한국어 기반 인공지능 서비스는 다른 나라와 비교하면 떨어질까?
    
    ⇒ 알고리즘이 학습할 수 있는 한국어 디지털 데이터 인프라가 취약하기 때문 
    

# 언어연구를 넘어 융합으로

- McKinsey(2011)
    - "빅데이터 활용: <br>
    1) 고객 행동 **예측** <br>
    2) **대처방안** 마련 <br>
        ⇒ 기업 경쟁력 강화, 생산성 향상, 비즈니스 혁신" <br>
        ⇒ 미래 예측 is 빅데이터 활용의 주요 목적

    - **추세 패턴 파악** (과거~현재 데이터 필요) ⇒ 미래 예측
- 텍스트 데이터: 인간성 총체적 반영
    - 경험
    - 마음
    - 이해방식

    - Q. 무엇을 이야기 하고 있는가? 

###  Digital Humanities (디지털 인문학): 
- 디지털 자원 활용한 인문사회과학과 전산적 연구의 융합분야

- 대표적 전산학 분야

| 데이터 분석              | 디지털 자원 생성       | 
|:--------------------------|:---------------------|
| 데이터 시각화        | 하이퍼텍스트         | 
| 데이터 마이닝    | 하이퍼미디어 | 
| 텍스트 마이닝   | 디지털 지도 | 
| 통계학    | 전자 출판 | 
|      |  정보 검색 | 


### 문화체학 Culturomics
- 위키피디아
- 구글 산업: 데이터 본질과 활용가치를 알아내 선도주자로 달림
    - 대체로 구글 ngram viewer 이용

### DATA SCIENCE

- using Big Data, 숨겨져 있는 유의미한 새로운 정보 추출, 전달하는 학문
- O'Reilly Media (2012), Laney, Kart( 2012) <br>
    1) 대량의 데이터 **수집**  <br>
    2) 적합한 형태로 **가공** <br>
    3) 데이터 **분석**  <br>
    4) 뜻을 효과적으로 전달 (**Storytelling**) <br>
    - 문법: 통계학

- **Data Science / Data Mining** 
    - **mining** 과 같이 <mark>시행착오 과정</mark> 속에서 <mark>숨겨져 있던 가치</mark>를 찾아냄

    - video content: 
        - 키워드를 사용하여 마케팅에 활용할 방안을 찾는다

# 여기 제대로 쓰기 (정리)
- 지향점:
    - 데이터는 손끝에서 항상 만들어지며, 기록된다
    - 숫자가 아니라 의미임
    - 주요 관찰 대상 중 1: 텍스트 데이터
    - 빅데이터는 개인을 넘어 사회와 문화의 기록
    - 궁극적 목표: 과거부터 현재의 기록을 활용해 미래를 예측
    - 상용적 목적이기는 하나 인간의 마음, 생각, 삶을 관찰

### 융합학문으로서 빅데이터
- Laney and Kart (2012) : 데이터과학의 핵심 능력
    - **Data Management** : 분산된 데이터 (분석에 필요한) 데이터 모으고 가공하는 데이터 처리
    - **Analytics Modeling** : ㅂㄴ석에 필요한 모형 만들고 결과 도출
    - **Buisness Analysis** : 해당 업종에 대한 이해
- Rogati (링크드인 수석 과학자) from Guardian (2012)
    > "모든 과학자는 데이터 과학자다. 내 견해로는 데이터 과학자는 반은 해커이고 반은 분석가다..."

- 에레즈 에이든, 장바티스트 미셸 (2015), 빅데이터 인문학: 진격의 서막, 사계절 => 특별 좌담 부록 중 송길영 (다음소프트 부사장)
    - 인문학적 통찰을 가진 전문가가 처음부터 필요
    - 어떤 데이터가 신호이고 어떤 데이터가 소음인지를 판단하려면 해당 영역에 대한 이해 필요
        => 그 분야와 기법에 정통한 사람이 다루어야 함
        
## 21세기 문헌학으로서 코퍼스 언어학

- 문헌학 (philology)
    - 언어학의 전신
    - text와 금석에 기록된 문자를 연구 대상. 과거를 연구
- 빅데이터 환경 지향점:
    - 인간의 언어, 마음, 사회, 문화에 대한 과거로부터 미래를 예측. 대개의 경우 인간
- 데이터 중 텍스트 데이터가 가장 많이 창출됨. 언어학자들이 누구보다 가장 효과적으로 다룰 수 있는 주제이다.
